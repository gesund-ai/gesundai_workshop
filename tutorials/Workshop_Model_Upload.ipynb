{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbb88d9",
   "metadata": {},
   "source": [
    "The following document describes the steps and provides instructions for successfully uploading user defined models and doing single and batch prediction on them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ef34c",
   "metadata": {},
   "source": [
    "Following is the outline of the notebook \n",
    "\n",
    "- [Step 1: Prepare the model upload bundle](#Step-1:-Prepare-the-model-upload-bundle)\n",
    "     - [Step 1.1: Prepare the `__init__.py`](#Step-1.1:-Prepare-the-__init__.py)\n",
    "     - [Step 1.2: Prepare the `model.py`](#Step-1.2:-Prepare-the-model.py)\n",
    "     - [Step 1.3: Prepare the `preprocess.py`](#Step-1.3:-Prepare-the-preprocess.py)\n",
    "     - [Step 1.4: Prepare the `postprocess.py`](#Step-1.4:-Prepare-the-postprocess.py)\n",
    "     - [Step 1.5: Prepare the `schema.py`](#Step-1.5:-Prepare-the-schema.py)\n",
    "     - [Step 1.6: Prepare the `loss.py`](#Step-1.6:-Prepare-the-loss.py)\n",
    "     - [Step 1.7: Prepare the `backbone.py`](#Step-1.7:-Prepare-the-backbone.py-[Optional])\n",
    "     - [Step 1.8: Prepare the `req.txt`](#Step-1.8:-Prepare-the-reqs.txt)\n",
    "     - [Step 1.9: Add the model file](#Step-1.9:-Add-the-model-file)\n",
    "     - [Step 1.10: Code Example](#Step-1.10:-Code-Example)\n",
    "     \n",
    "- [Tutorials](#Tutorials)\n",
    "    - [Helper Functions](#Helper-Functions)\n",
    "    - [Tutorial: How to download template framework](#Tutorial:-How-to-download-template-framework)\n",
    "    - [Tutorial: How to check existing namespaces](#Tutorial:-How-to-check-existing-namespaces)\n",
    "    - [Tutorial: Model Upload API Usecases](#Tutorial:-Model-Upload-API-Usecases)\n",
    "    - [Tutorial: Single prediction using the uploaded model](#Tutorial:-Single-prediction-using-the-uploaded-model)\n",
    "    - [Tutorial: Batch prediction using the uploaded model](#Tutorial:-Batch-prediction-using-the-uploaded-model)\n",
    "    - [Tutorial: How to check the batch prediction status](#Tutorial:-How-to-check-the-batch-prediction-status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34d8aa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1: Prepare the model upload bundle\n",
    "\n",
    "In this section, you will prepare the model upload bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e33dd3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Model upload bundle consists of the following files\n",
    "\n",
    "<pre>\n",
    "my_model_bundle/\n",
    " |--- __init__.py\n",
    " |--- model.py\n",
    " |--- preprocess.py\n",
    " |--- postprocess.py\n",
    " |--- schema.py\n",
    " |--- reqs.txt\n",
    " |--- model.h5\n",
    " |--- loss.py\n",
    " |--- backbone.py [ Optional ] \n",
    "</pre>\n",
    "\n",
    "We will look into details of what each file should contain to make everything work.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> We need a <zip_files_name>.zip file to upload in the model upload api\n",
    "</div>\n",
    "\n",
    "During upload these files should be zipped together at the file level and not the folder level. Meaning when we unzip the zipped file it should **not** contain any folders inside this bundle set. \n",
    "\n",
    "Inorder to do get the zip file run the following linux commands\n",
    "\n",
    "<pre>\n",
    "`cd my_model_bundle/`\n",
    "`zip model_upload.zip *.*`\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00469c3f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.1: Prepare the `__init__.py`\n",
    "\n",
    "This section provides the information on how to create the `__init__.py` file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8ada674",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `__init__.py` file contains all the model classes imported from the respective python files. This file is used to convert the folder into a package.\n",
    "\n",
    "\n",
    "*For example* : The file can look like this\n",
    "\n",
    "<pre>\n",
    "from .model import <mark style=\"background-color:yellow;\">MyNet</mark> # Replace with your model class name\n",
    "from .schema import Response\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470812e3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.2: Prepare the `model.py`\n",
    "\n",
    "This section provides the information on how to create the `model.py` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec6a9d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are three main concerns that should be took care in the `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7782f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1. Imports in the file** \n",
    "\n",
    "All the dependencies should be imported.\n",
    "\n",
    "\n",
    "*Example*\n",
    "<pre>\n",
    "    \n",
    "import time\n",
    "import functools\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from logger import AppLogger\n",
    "from register.register import modelservice\n",
    "from model.base_models import TensorflowModel\n",
    "from .preprocess import Preprocess\n",
    "from .postprocess import Postprocess\n",
    "\n",
    "logger = AppLogger(__name__).get_logger()\n",
    "\n",
    "\n",
    "__all__ = [<mark style=\"background-color:yellow;\">'FancyModelX' </mark>] # Replace with your own class name\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    pass\n",
    "    \n",
    "</pre>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b> You can <strong>download the pre-existing templates</strong> API to for a specific framework - problem - architecture combination and extend the class to write your own model class\n",
    "</div>\n",
    "\n",
    "Follow this: [Tutorial: How to download template framework](#Tutorial:-How-to-download-template-framework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e77684",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. Model Class Structure** \n",
    "\n",
    "The class structure should be like the following Example\n",
    "\n",
    "<pre>\n",
    "@modelservice.register_module(name=<mark style=\"background-color:yellow;\">'fancynetmodelx'</mark>, default=False) # Replace with your own namespace\n",
    "class <mark style=\"background-color:yellow;\">FancyModelX</mark>(TensorflowModel): # Modify as per your class name \n",
    "    def __init__(self, model_path) -> None:\n",
    "        \"\"\"\n",
    "        Function to initialize the class\n",
    "        \n",
    "        :param model_path: path to the model artifact\n",
    "        :param model_path: str\n",
    "        \"\"\"\n",
    "        super().__init__(model_path) \n",
    "        self.model_path = model_path\n",
    "        self.preprocess = Preprocess()\n",
    "        self.postprocess = Postprocess()\n",
    "        # ADD ANY ADDITIONAL ATTRIBUTES IF REQUIRED\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"\n",
    "        Function to load the model.\n",
    "        \"\"\"\n",
    "        self.model = super().load()\n",
    "        # The function loads the model using the \n",
    "        # loading logic mentioned in the base model template\n",
    "        # ADD ANY ADDITIONAL LOGIC AS PER YOUR USECASE\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        A Wrapper Function to load the model.\n",
    "        \"\"\"\n",
    "        pass # Your model load logic goes here\n",
    "        \n",
    "    def _model_output(self, input_):\n",
    "        \"\"\"\n",
    "        A Wrapper Function to get the model output by calling the predict function.\n",
    "        \n",
    "        :param input_: input array for the model prediction\n",
    "        :param input_: numpy array / tensor array\n",
    "        \"\"\"\n",
    "        pass # Your model output logic goes here\n",
    "\n",
    "    def predict(self, input_):\n",
    "        \"\"\"\n",
    "        Function to implement the prediction function of the model\n",
    "        \n",
    "        :param input_: input array for the model prediction\n",
    "        :param input_: numpy array / tensor array\n",
    "        \"\"\"\n",
    "        pass # Your prediction logic goes here\n",
    "\n",
    "    def loss(self, y_pred, y_true): \n",
    "        \"\"\"\n",
    "        Function to implement the loss function of the model\n",
    "        \n",
    "        :param y_pred: predicted target\n",
    "        :param y_pred: numpy array / tensor array\n",
    "        :param y_true: actual value / ground truth\n",
    "        :param y_true: numpy array / tensor array\n",
    "        \"\"\"\n",
    "        pass  # Your loss logic goes here\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7caa0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**3. Namespaces**\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>NOTE:</b> Here the namespace used to register in the model should be <strong>unique</strong>\n",
    "</div>\n",
    "\n",
    "You can follow this [Tutorial: How to check existing namespaces](#Tutorial:-How-to-check-existing-namespaces) to check the default and user defined namespaces already present in the database. This will give you an idea how the namespaces should look like or what all namespaces are existing to avoid duplicate namespaces.\n",
    "\n",
    "\n",
    "This line of code `@modelservice.register_module(name='fancynetmodelx', default=False)` is responsible for registering the model class.\n",
    "\n",
    "Class is registered with the given namespace `name='fancynetmodelx'`.\n",
    "\n",
    "Here, `default=False`, the default should be set to `False` so that the class is considered as user-defined. In any case if the there exists a conflict with the namespaces then **Namespace already exist** error is raised. \n",
    "\n",
    "And, if the `default=True` the class will not register in the platform. **The access is forbidden for making a user-defined to a default class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711f31f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**4. Adding the public object list**\n",
    "\n",
    "This line of code `__all__ = ['FancyModelX']` ensures that the model class name can be accessed during the import. So the name of the model class should be added to the ` __all__` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a295bb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.3: Prepare the `preprocess.py`\n",
    "\n",
    "This section gives the info on how to create `preprocess.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc8192",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `preprocess.py` contains three concerns\n",
    "\n",
    "**1. Imports in the file**\n",
    "\n",
    "*Example*\n",
    "<pre>\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Union\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34924d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. Preprocess function definition**\n",
    "\n",
    "*Example* \n",
    "\n",
    "\n",
    "<pre>\n",
    "def custom_preprocess_fxn(input_, batch=False) -> Union[list|array]:\n",
    "    \"\"\"\n",
    "    Function for customized preprocessing logic\n",
    "    \n",
    "    :param input_: raw input value for preprocessing\n",
    "    :param input_: numpy array / image buffer \n",
    "    :param batch: bool value for switching batch prediction vs single prediction preprocess logic\n",
    "    :param batch: bool\n",
    "    \n",
    "    :returns list | array: list of preprocessed arrays\n",
    "    \n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # ========================== The preprocess logic could look like this\n",
    "    # if batch:\n",
    "    #    return np.asarray(\n",
    "    #        [np.resize(inp, (512, 512, 3)) / 255.0 for inp in input])\n",
    "    # input = np.resize(input, (512, 512, 3))\n",
    "    # input = input / 255.0\n",
    "    # return np.expand_dims(input, 0)\n",
    "    # ==========================\n",
    "\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd99e21",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**3. Preprocess Class Structure**\n",
    "\n",
    "<pre>\n",
    "class Preprocess:\n",
    "    def __init__(self) -> None:\n",
    "        self._preprocess = custom_preprocess_fxn  # Name of the preprocess function goes here\n",
    "\n",
    "    def __call__(self, input_, batch=False):\n",
    "        return self._preprocess(input_, batch)\n",
    "</pre>\n",
    "\n",
    "This class `Preprocess` is imported in the `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3393d1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>NOTE:</b> The Namespace used for registering in the respective files should be <strong>all same across classes and unique</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63bea1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.4: Prepare the `postprocess.py`\n",
    "\n",
    "This section gives the information on how to create `postprocess.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82a9b1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are there three main concerns in the `postprocess.py`\n",
    "\n",
    "\n",
    "**1. Imports**\n",
    "\n",
    "<pre>\n",
    "\n",
    "import numpy as np\n",
    "from schema import Response\n",
    "from typing import Union\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d625ff9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. Function definitions**\n",
    "\n",
    "<pre>\n",
    "\n",
    "def custom_postprocess_fxn(output, batch=False, context=None, threshold=0.0) -> Union[list|dict]:\n",
    "    \"\"\"\n",
    "    Function for customized postprocess function\n",
    "    \n",
    "    :param output: output array for postprocessing\n",
    "    :param output: numpy array / tensor array \n",
    "    :param batch: bool value to switch for single prediction vs batch prediction\n",
    "    :param batch: bool\n",
    "    :param context: This parameter is in progress\n",
    "    :param context: None\n",
    "    :param threshold: Value for thresholding the prediction\n",
    "    :param threshold: float\n",
    "    \n",
    "    :returns list[dict] | dict: list if batch else dictionary\n",
    "    \n",
    "    Ensure that output dictionary matches the Response model designed in the schema.py\n",
    "    \"\"\"\n",
    "    pass\n",
    "    # ADD YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # ====================================== The logic for post process could look like this\n",
    "    # def _postprocess(output):\n",
    "    #    prob = softmax(np.asarray(output[0]))\n",
    "    #    cls_idx = np.argmax(prob)\n",
    "    #    conf = prob[cls_idx]\n",
    "    #    output = {'prediction_class': int(cls_idx),\n",
    "    #              'confidence': float(conf),\n",
    "    #              'logits': output[0].tolist() if isinstance(output[0], np.ndarray) else list(output[0]),\n",
    "    #              'status': 200}\n",
    "    #    return output\n",
    "    # if batch:\n",
    "    #    output_response = []\n",
    "    #    pred = output\n",
    "    #    for i in range(len(pred)):\n",
    "    #        prediction = _postprocess([pred[i]])\n",
    "    #        output_response.append(prediction)\n",
    "    #    return output_response\n",
    "    # else:\n",
    "    #    return _postprocess(output)\n",
    "    # ======================================= \n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f278fa7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**3. Postprocess Class Structure**\n",
    "\n",
    "\n",
    "<pre>\n",
    "class Postprocess:\n",
    "    def __init__(self) -> None:\n",
    "        self._postprocess_fxn = custom_postprocess_fxn # Name of the customized postprocess function goes here\n",
    "\n",
    "    def __call__(self, input_, batch=False, context=None):\n",
    "        return self._postprocess_fxn(input_, batch, context)\n",
    "\n",
    "</pre>\n",
    "\n",
    "\n",
    "This class `Postprocess` is imported in the `model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d787273",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>NOTE:</b> The Namespace used for registering in the respective files should be <strong>all same across classes and unique</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0cd291",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.5: Prepare the `schema.py`\n",
    "\n",
    "This section gives the information on how to create `schema.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab48ba8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are two main concerns in the `schema.py`\n",
    "\n",
    "\n",
    "**1. Imports**\n",
    "<pre>\n",
    "from pydantic import BaseModel\n",
    "from register import outschema\n",
    "</pre>\n",
    "\n",
    "We need to import the `outschema` for registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29963",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. Response class structure**\n",
    "\n",
    "<pre>\n",
    "@outschema.register_module(<mark style=\"background-color:yellow;\">'fancynetmodelx'</mark>, default=False) # Replace with your own namespace\n",
    "class Response(BaseModel):\n",
    "    prediction_class: int\n",
    "    confidence: float\n",
    "    logits: list\n",
    "\n",
    "</pre>\n",
    "\n",
    "This line of code `@outschema.register_module('fancynetmodelx', default=False)` registers the `Reponse` class. The response class is used define the schema for model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802e327",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>NOTE:</b> The Namespace used for registering in the respective files should be <strong>all same across classes and unique</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08615c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.6: Prepare the `loss.py`\n",
    "\n",
    "This section gives the information on how to create `loss.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11187c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The loss function is responsible for calculating the loss metrics whenever a batch prediction happens\n",
    "\n",
    "You can define the loss function logic inside a class or function inside  `loss.py` and implement in the `model.py` file, in the loss class method of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67437deb",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "class MyLoss:\n",
    "    def __init__(self):\n",
    "        pass # your logic here\n",
    "    \n",
    "    def loss_function(self, y_pred, y_true) -> float:\n",
    "        \"\"\"\n",
    "        Function to calculate loss \n",
    "        \n",
    "        :param y_pred: predicted value\n",
    "        :param y_pred: list / array\n",
    "        :param y_true: actual value\n",
    "        :param y_true: list / array\n",
    "        \n",
    "        :returns float\n",
    "        \"\"\"\n",
    "        pass # Your code here\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f693a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.7: Prepare the `backbone.py` [Optional]\n",
    "\n",
    "This section gives the information on how to create the `backbone.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce5f87",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `backbone.py` is required in cases where the model architecture is defined and is used in the `model.py` file. Inside the `load` function we need to create an instance of the model architecture and send the instance to the inherited `load` function so that the weights are loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7fc674",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.8: Prepare the `reqs.txt`\n",
    "\n",
    "This section gives the information on how to create `reqs.txt` file"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8b0c3fce",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The requirements text file should contain all the packages that is used across all the files\n",
    "\n",
    "*Example*\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82536f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1.9: Add the model file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef43e68",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The model weights file should be added in the directory\n",
    "\n",
    "It can be one of the following\n",
    "\n",
    "1. `model.h5`\n",
    "2. `model.pt`\n",
    "3. `model.onnx`\n",
    "4. `tensorflow_checkpoints`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7178467",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>NOTE:</b> There are special Use cases with respect to how the model upload API works with different set of combinations. \n",
    "</div>\n",
    "\n",
    "To know more about this check this section [Tutorials: Model Upload API Usecases](#Tutorial:-Model-Upload-API-Usecases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e745f",
   "metadata": {},
   "source": [
    "### Step 1.10: Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f39b9",
   "metadata": {},
   "source": [
    "**1. `__init__.py`**\n",
    "\n",
    "\n",
    "\n",
    "<pre>\n",
    "\n",
    "from .model import MyNet\n",
    "from .schema import Response\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cecee0",
   "metadata": {},
   "source": [
    "**2. model.py**\n",
    "\n",
    "<pre>\n",
    "import numpy as np\n",
    "\n",
    "from logger import AppLogger\n",
    "from register.register import modelservice\n",
    "from core.engine.base_models import TensorflowModel\n",
    "from .preprocess import Preprocess\n",
    "from .postprocess import Postprocess\n",
    "\n",
    "logger = AppLogger(__name__).get_logger()\n",
    "\n",
    "__all__ = ['MyNet']\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "@modelservice.register_module(name='MyNet', default=False)\n",
    "class MyNet(TensorflowModel):\n",
    "    def __init__(self, model_path) -> None:\n",
    "        super().__init__(model_path)\n",
    "        self.model_path = model_path\n",
    "        self.preprocess = Preprocess()\n",
    "        self.preprocess(np.zeros((100, 100, 3)), False)\n",
    "        self.postprocess = Postprocess()\n",
    "        self.num_classes = 1\n",
    "        self.class_mapping = {1: 'Positive', 0: 'Negative'}\n",
    "\n",
    "    def _load_model(self):\n",
    "        self.model = super().load()\n",
    "\n",
    "    def load(self):\n",
    "        self._load_model()\n",
    "\n",
    "    def _model_output(self, input):\n",
    "        y_pred = self.model.predict(input)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, input):\n",
    "        y_pred = self._model_output(input)\n",
    "        return y_pred\n",
    "\n",
    "    def loss(self, y_pred, gts):\n",
    "        if not any(isinstance(el, list) for el in gts):\n",
    "            gts = np.asarray(list(map(lambda x: int(x), gts)))\n",
    "        # Apply loss function\n",
    "        _loss_function = tf.keras.losses.CategoricalCrossentropy(\n",
    "            reduction='none')\n",
    "        gts_encoder = np.zeros((gts.size, self.num_classes))\n",
    "        gts_encoder[np.arange(gts.size), gts] = 1\n",
    "        losses = _loss_function(y_pred, gts_encoder).numpy()\n",
    "\n",
    "        return losses.tolist()\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d52e0c",
   "metadata": {},
   "source": [
    "**3. preprocess.py**\n",
    "\n",
    "<pre>\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def custom_preprocess_fxn(input, batch=False):\n",
    "    if batch:\n",
    "        return np.asarray(\n",
    "            [np.resize(inp, (64, 64, 3)) / 255.0 for inp in input])\n",
    "    input = np.resize(input, (64, 64, 3)) / 255.0\n",
    "    return np.expand_dims(input, 0)\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self) -> None:\n",
    "        self._preprocess = custom_preprocess_fxn\n",
    "\n",
    "    def __call__(self, input, batch=False):\n",
    "        if batch:\n",
    "            return np.asarray(\n",
    "                [np.resize(inp, (64, 64, 3)) / 255.0 for inp in input])\n",
    "        input = np.resize(input, (64, 64, 3)) / 255.0\n",
    "        return np.expand_dims(input, 0)\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95afdb",
   "metadata": {},
   "source": [
    "**4. postprocess.py**\n",
    "\n",
    "\n",
    "<pre>\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def custom_postprocess_fxn(model_output, batch=False, context=None, threshold=0.0):\n",
    "    def _postprocess(output):\n",
    "        prob = softmax(np.array(output[0]))\n",
    "        confidence = output[0][0]\n",
    "        prediction_class = 0\n",
    "        if threshold > 0:\n",
    "            prediction_class = 1 if confidence > threshold else 0\n",
    "        else:\n",
    "            prediction_class = int(confidence)\n",
    "\n",
    "        output = {'prediction_class': prediction_class,\n",
    "                  'confidence': float(confidence),\n",
    "                  'logits': prob.tolist(),\n",
    "                  'status': 200}\n",
    "        return output\n",
    "    if batch:\n",
    "        return [_postprocess([val]) for idx, val in enumerate(model_output)]\n",
    "    else:\n",
    "        return _postprocess(model_output)\n",
    "\n",
    "\n",
    "class Postprocess:\n",
    "    def __init__(self) -> None:\n",
    "        self._postprocess_fxn = custom_postprocess_fxn\n",
    "\n",
    "    def __call__(self, input, batch=False, context=None):\n",
    "        return self._postprocess_fxn(input, batch, context)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3040d74",
   "metadata": {},
   "source": [
    "**5. schema.py**\n",
    "\n",
    "<pre>\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from register import outschema\n",
    "\n",
    "\n",
    "@outschema.register_module('MyNet', default=False)\n",
    "class Response(BaseModel):\n",
    "    prediction_class: int\n",
    "    confidence: float\n",
    "    logits: list\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d2226",
   "metadata": {},
   "source": [
    "**6.reqs.txt**\n",
    "\n",
    "<pre>\n",
    "tensorflow-cpu\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083a147",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tutorials \n",
    "\n",
    "This section goes over the details of using the **model upload API**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14766fb2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Helper Functions\n",
    "\n",
    "Execute this section to bring the helper functions on the memory for further code execution of the API's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110f0a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymongo\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a127c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modify the config parameters as per convenience\n",
    "config = {\n",
    "    'mongodb_username': '',  # Add username\n",
    "    'mongodb_userpass': '',  # Add password\n",
    "    'mongodb_host': 'localhost',\n",
    "    'mongodb_port': '27017',\n",
    "}\n",
    "\n",
    "\n",
    "def send_request(payload, endpoint, request_type, params=None):\n",
    "    \"\"\"Function to send the request to the model post or get type\"\"\"\n",
    "    # set headers to api\n",
    "    headers = {\n",
    "        'accept': 'application/json', \n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    \n",
    "    # Post the data on the api\n",
    "    if request_type == 'post':\n",
    "        if params:\n",
    "            response = requests.post(endpoint, params=params, json=payload, headers=headers)\n",
    "        else:\n",
    "            response = requests.post(endpoint, json=payload, headers=headers)\n",
    "    else:\n",
    "        if params:\n",
    "            response = requests.get(endpoint, params=params, json=payload, headers=headers)\n",
    "        else:\n",
    "            response = requests.get(endpoint, json=payload, headers=headers)\n",
    "    \n",
    "    print(\"status code: \", response.status_code)\n",
    "    print(\"json response: \", response.json())\n",
    "\n",
    "\n",
    "def get_validation_progress():\n",
    "    \"\"\"This function gets the status of progress of validation run.\"\"\"\n",
    "    user_name = config['mongodb_username']\n",
    "    user_pass = config['mongodb_userpass']\n",
    "    host = config['mongodb_host']\n",
    "    port = config['mongodb_port']\n",
    "    client = pymongo.MongoClient(f\"mongodb://{user_name}:{user_pass}@{host}:{port}\")\n",
    "    db = client['Frontend']\n",
    "    collection = db['ValidationSummary']\n",
    "    for doc in collection.find({'batch_job_id': batch_job_id}, {'progress':1}):\n",
    "        print('progress: ', doc['progress'])\n",
    "        \n",
    "\n",
    "def fetch_model_card_from_db(model_id):\n",
    "    \"\"\"This function fetches the model card from the mongo database.\"\"\"\n",
    "    user_name = config['mongodb_username']\n",
    "    user_pass = config['mongodb_userpass']\n",
    "    host = config['mongodb_host']\n",
    "    port = config['mongodb_port']\n",
    "    client = pymongo.MongoClient(f\"mongodb://{user_name}:{user_pass}@{host}:{port}\")\n",
    "    db = client['Model']\n",
    "    collection = db['ModelCard']\n",
    "    \n",
    "    for doc in collection.find({'model_id': model_id}):\n",
    "        pprint.pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03ebef",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: How to download template framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7e2ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download pre-existing template\n",
    "\n",
    "host_name = \"http://127.0.0.1\" # put here the host name\n",
    "port_number = \"8015\" # put here the port number \n",
    "endpoint = \"manage/models/template/zip\" # put here the endpoint\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put here the framework of your choice\n",
    "    \"problem\": \"classification\", # put here the problem of your choice\n",
    "    \"architecture\": \"resnet50\" # put here the architecture of your choice\n",
    "}\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "payload = {}\n",
    "headers = {\n",
    "        'accept': 'application/json', \n",
    "        'Content-Type': 'application/json'\n",
    "}\n",
    "resp = requests.post(url, json=payload, headers=headers, params=params) \n",
    "print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b8ab3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Write the received binary stream into a zip file\n",
    "with open('template.zip', 'wb') as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77693b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# unzip the template file using the linux command\n",
    "!unzip template.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ace88",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: How to check existing namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a674b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check Existing NameSpaces\n",
    "\n",
    "host_name = \"http://127.0.0.1\" # put here the host name\n",
    "port_number = \"8015\" # put here the port number \n",
    "endpoint = \"manage/models/namespaces\" # put here the endpoint\n",
    "\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "payload = {}\n",
    "headers = {\n",
    "        'accept': 'application/json', \n",
    "        'Content-Type': 'application/json'\n",
    "}\n",
    "resp = requests.get(url, json=payload, headers=headers)\n",
    "print(resp.status_code)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed5184",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: Model Upload API Usecases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7014774",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da68862",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**&#9654; Case 1: Update prebuilt model with custom model layers**\n",
    "\n",
    "Case when we update the model architecture and add a new model to the database. \n",
    "In this case we require.\n",
    "\n",
    "- The `model.py` file with namespace registered on the class. Ex: `@modelservice.register_module(name='resnet50x_test', default=False)`, the default flag should be set to False in order to register it as a user-defined module.\n",
    "- The `schema.py` file should contain the same namespace registered to the model class. Ex: `@outschema.register_module('resnet50x_test', default=False)`\n",
    "- The Namespaces should be unique else it will raise a <strong>Namespace is already present exception</strong>\n",
    "\n",
    " <b>Parameter Combination Example</b>\n",
    " <pre>\n",
    " *Type: Classification*\n",
    " *Framework: tensorflow*\n",
    " *Architecture: resnet*\n",
    " *customize: True*\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201e36f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9aab5e7d3f4e93a2a3d0edd9d1c2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.zip', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Upload the zip folder to the platform\n",
    "upload = FileUpload(accept='.zip', multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0776a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Save the uploaded zip file\n",
    "zip_file_path = os.getcwd() + '/user_model.zip'\n",
    "with open(zip_file_path, 'wb') as output_file: \n",
    "    for uploaded_filename in upload.value:\n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content) \n",
    "print(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905305b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Send the zip file to the model zip upload api\n",
    "payload = {}\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put the name of the framework here\n",
    "    \"problem\": \"multiclass-classification\",  # put the problem with respect to your choice and the combination\n",
    "    \"architecture\": \"resnet50x_test\" # put the name of the architecture\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = 'manage/models/upload/zip' # put the endpoint here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\" \n",
    "\n",
    "files = {'model_zip': open(zip_file_path, 'rb')} # reads the model zip file\n",
    "resp = requests.post(url, files=files, params=params) # posts the request\n",
    "print(resp.json())\n",
    "\n",
    "######\n",
    "# Response\n",
    "#   - model_id : str\n",
    "#   - model_zip_path : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b19b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Update the ModelCard in the database\n",
    "\n",
    "# Model card - # Note the fields from UI are different from the fields in the figma \n",
    "# enter the details of the model here.\n",
    "payload = {\n",
    "  \"model_architecture\": \"resnet50x_test\",\n",
    "  \"model_id\": \"61e80621b9d1e809e220d52a\", # put the model id received from the upload api here\n",
    "  \"model_framework\": \"tensorflow\",\n",
    "  \"framework_version\": \"1\",\n",
    "  \"reqs\": \"tf_reqs.txt\",\n",
    "  \"model_version\": \"1\",\n",
    "  \"model_url\": \"resnet-50.h5\",\n",
    "  \"model_size\": \"150\",\n",
    "  \"class_mappings\": { \"0\" : \"No DR\", \"1\" : \"Mild\", \"2\" : \"Moderate\", \"3\" : \"Severe\", \"4\" : \"Proliferate DR\" },\n",
    "  \"problem\": \"multiclass-classification\",\n",
    "  \"category\": \"EyeScan\",\n",
    "  \"tags\": [\n",
    "    \"retinopathy\"\n",
    "  ],\n",
    "  \"model_train_specs\": {},\n",
    "  \"model_vendor_id\": \"vendor1\",\n",
    "  \"created_timestamp\": \"\",\n",
    "  \"input_shape\": [320, 320]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # use the model zip path recieved from manage/models/upload/zip\n",
    "    'model_zip_path': 'user_models/multiclass-classification/tensorflow/model_61e80621b9d1e809e220d52a', \n",
    "    'only_model': False # This field is inverse to the customize field value mentioned in the github wiki\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = \"manage/models/db/add\" # put the end point here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "\n",
    "send_request(payload, url, \"post\", params)\n",
    "######\n",
    "# Response\n",
    "#   - status : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd91eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Check if the model card is added to the database\n",
    "fetch_model_card_from_db('61e80621b9d1e809e220d52a') # input is model id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfeee11",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**&#9654; Case 2: Update prebuilt model with only new model weights file.**\n",
    "\n",
    "Case where we need to update only the model\n",
    "\n",
    "\n",
    "In this case we require\n",
    "\n",
    "- The model weights file (.h5) or (.hdf5)\n",
    "- The `model.py` file will be ignored if passed.\n",
    "- The given namespace should be same as the architecture name.\n",
    "\n",
    " <b>Parameter Combination Example</b>\n",
    " <pre>\n",
    " *Type: Classification*\n",
    " *Framework: tensorflow*\n",
    " *Architecture: resnet*\n",
    " *customize: False*\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c05bafb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe858af56554ff5a20281b3c94ff241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.zip', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Upload the zip folder to the platform\n",
    "upload = FileUpload(accept='.zip', multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae83d10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Save the uploaded zip file\n",
    "zip_file_path = os.getcwd() + '/user_model.zip'\n",
    "with open(zip_file_path, 'wb') as output_file: \n",
    "    for uploaded_filename in upload.value:\n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content) \n",
    "print(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa33023",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Send the zip file to the model zip upload api\n",
    "payload = {}\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put the name of the framework here\n",
    "    \"problem\": \"multiclass-classification\",  # put the problem with respect to your choice and the combination\n",
    "    \"architecture\": \"resnet50x_test\" # put the name of the architecture\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = 'manage/models/upload/zip' # put the endpoint here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\" \n",
    "\n",
    "files = {'model_zip': open(zip_file_path, 'rb')} # reads the model zip file\n",
    "resp = requests.post(url, files=files, params=params) # posts the request\n",
    "print(resp.json())\n",
    "\n",
    "######\n",
    "# Response\n",
    "#   - model_id : str\n",
    "#   - model_zip_path : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec4dac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Update the ModelCard in the database\n",
    "\n",
    "# Model card - # Note the fields from UI are different from the fields in the figma \n",
    "# enter the details of the model here.\n",
    "payload = {\n",
    "  \"model_architecture\": \"resnet50x_test\",\n",
    "  \"model_id\": \"61e80621b9d1e809e220d52a\", # put the model id received from the upload api here\n",
    "  \"model_framework\": \"tensorflow\",\n",
    "  \"framework_version\": \"1\",\n",
    "  \"reqs\": \"tf_reqs.txt\",\n",
    "  \"model_version\": \"1\",\n",
    "  \"model_url\": \"resnet-50.h5\",\n",
    "  \"model_size\": \"150\",\n",
    "  \"class_mappings\": { \"0\" : \"No DR\", \"1\" : \"Mild\", \"2\" : \"Moderate\", \"3\" : \"Severe\", \"4\" : \"Proliferate DR\" },\n",
    "  \"problem\": \"multiclass-classification\",\n",
    "  \"category\": \"EyeScan\",\n",
    "  \"tags\": [\n",
    "    \"retinopathy\"\n",
    "  ],\n",
    "  \"model_train_specs\": {},\n",
    "  \"model_vendor_id\": \"vendor1\",\n",
    "  \"created_timestamp\": \"\",\n",
    "  \"input_shape\": [320, 320]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # use the model zip path recieved from manage/models/upload/zip\n",
    "    'model_zip_path': 'user_models/multiclass-classification/tensorflow/model_61e819ad17ce37cfc59df612', \n",
    "    'only_model': True # This field is inverse to the customize field value mentioned in the github wiki\n",
    "}\n",
    "\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = \"manage/models/db/add\" # put the end point here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "\n",
    "send_request(payload, url, \"post\", params)\n",
    "######\n",
    "# Response\n",
    "#   - status : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92588493",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Check if the model card is added to the database\n",
    "fetch_model_card_from_db('61e80621b9d1e809e220d52a') # input is model id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63741be5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**&#9654; Case 3: Upload new architecture from scratch (FancyNet)**\n",
    "\n",
    "Case when new architecture is uploaded\n",
    "\n",
    "In this case we require\n",
    "\n",
    "- In case for architecture is None, customize is automatically True, only_model will be set to false\n",
    "- The `model.py` file will be checked for namespace and uniqueness (FancyNet). Ex: `@modelservice.register_module(name='fancymodelx', default=False)`\n",
    "- `schema.py` should contain the same namespace as the namespace used for registering the `model.py` Ex: `@outschema.register_module('fancymodelx', default=False)`\n",
    "- Here, FancyNet simply represents any of the modelNET that the user would define.\n",
    "\n",
    "<b>Parameter Combination Example</b>\n",
    "<pre>\n",
    "*Type: Classification*\n",
    "*Framework: tensorflow*\n",
    "*Architecture: None*\n",
    "*customize: True*\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5449a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Upload the zip folder to the platform\n",
    "upload = FileUpload(accept='.zip', multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec216b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Save the uploaded zip file\n",
    "zip_file_path = os.getcwd() + '/user_model.zip'\n",
    "with open(zip_file_path, 'wb') as output_file: \n",
    "    for uploaded_filename in upload.value:\n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content) \n",
    "print(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9141d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Send the zip file to the model zip upload api\n",
    "payload = {}\n",
    "\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put the name of the framework here\n",
    "    \"problem\": \"multiclass-classification\", # put the problem with respect to your choice and the combination\n",
    "    \"architecture\": \"fancynet_modelx\"  # put the name of the architecture\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = 'manage/models/upload/zip' # put the endpoint here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\" \n",
    "\n",
    "files = {'model_zip': open(zip_file_path, 'rb')} # reads the model zip file\n",
    "resp = requests.post(url, files=files, params=params) # posts the request\n",
    "print(resp.json())\n",
    "\n",
    "######\n",
    "# Response\n",
    "#   - model_id : str\n",
    "#   - model_zip_path : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4b18a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Update the ModelCard in the database\n",
    "\n",
    "# Model card - # Note the fields from UI are different from the fields in the figma \n",
    "# enter the details of the model here.\n",
    "payload = {\n",
    "  \"model_architecture\": \"\",\n",
    "  \"model_id\": \"61e80621b9d1e809e220d52a\", # put the model id received from the upload api here\n",
    "  \"model_framework\": \"tensorflow\",\n",
    "  \"framework_version\": \"1\",\n",
    "  \"reqs\": \"tf_reqs.txt\",\n",
    "  \"model_version\": \"1\",\n",
    "  \"model_url\": \"resnet-50.h5\",\n",
    "  \"model_size\": \"150\",\n",
    "  \"class_mappings\": { \"0\" : \"No DR\", \"1\" : \"Mild\", \"2\" : \"Moderate\", \"3\" : \"Severe\", \"4\" : \"Proliferate DR\" },\n",
    "  \"problem\": \"multiclass-classification\",\n",
    "  \"category\": \"EyeScan\",\n",
    "  \"tags\": [\n",
    "    \"retinopathy\"\n",
    "  ],\n",
    "  \"model_train_specs\": {},\n",
    "  \"model_vendor_id\": \"vendor1\",\n",
    "  \"created_timestamp\": \"\",\n",
    "  \"input_shape\": [320, 320]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # use the model zip path recieved from manage/models/upload/zip\n",
    "    'model_zip_path': 'user_models/multiclass-classification/tensorflow/model_61e819ad17ce37cfc59df612', \n",
    "    'only_model': False # This field is inverse to the customize field value mentioned in the github wiki\n",
    "}\n",
    "\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = \"manage/models/db/add\" # put the end point here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "\n",
    "send_request(payload, url, \"post\", params)\n",
    "######\n",
    "# Response\n",
    "#   - status : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de5c9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Check if the model card is added to the database\n",
    "fetch_model_card_from_db('61e80621b9d1e809e220d52a') # input is model id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba36a0a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**&#9654; Case 4: Upload the newly added architecture with new model architecture**\n",
    "\n",
    "Case when newly added architecture is used for new model\n",
    "\n",
    "In this case we require\n",
    "\n",
    "- customise is true hence model file and out schema will checked for namespace uniqueness (namespace should not match FancyNet or default namespaces)\n",
    "\n",
    "\n",
    "<b>Parameter Combination Example</b>\n",
    "<pre>\n",
    "*Type: Classification*\n",
    "*Framework: tensorflow*\n",
    "*Architecture: FancyNet*\n",
    "*customize: True*\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb3890",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Upload the zip folder to the platform\n",
    "upload = FileUpload(accept='.zip', multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15351af2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Save the uploaded zip file\n",
    "zip_file_path = os.getcwd() + '/user_model.zip'\n",
    "with open(zip_file_path, 'wb') as output_file: \n",
    "    for uploaded_filename in upload.value:\n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content) \n",
    "print(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5af160",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Send the zip file to the model zip upload api\n",
    "payload = {}\n",
    "\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put the name of the framework here\n",
    "    \"problem\": \"multiclass-classification\", # put the problem with respect to your choice and the combination\n",
    "    \"architecture\": \"fancynet_modelx\"  # put the name of the architecture\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = 'manage/models/upload/zip' # put the endpoint here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\" \n",
    "\n",
    "files = {'model_zip': open(zip_file_path, 'rb')} # reads the model zip file\n",
    "resp = requests.post(url, files=files, params=params) # posts the request\n",
    "print(resp.json())\n",
    "\n",
    "######\n",
    "# Response\n",
    "#   - model_id : str\n",
    "#   - model_zip_path : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d8523",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Update the ModelCard in the database\n",
    "\n",
    "# Model card - # Note the fields from UI are different from the fields in the figma \n",
    "# enter the details of the model here.\n",
    "payload = {\n",
    "  \"model_architecture\": \"fancynet_modelx\",\n",
    "  \"model_id\": \"61e80621b9d1e809e220d52a\", # put the model id received from the upload api here\n",
    "  \"model_framework\": \"tensorflow\",\n",
    "  \"framework_version\": \"1\",\n",
    "  \"reqs\": \"tf_reqs.txt\",\n",
    "  \"model_version\": \"1\",\n",
    "  \"model_url\": \"resnet-50.h5\",\n",
    "  \"model_size\": \"150\",\n",
    "  \"class_mappings\": { \"0\" : \"No DR\", \"1\" : \"Mild\", \"2\" : \"Moderate\", \"3\" : \"Severe\", \"4\" : \"Proliferate DR\" },\n",
    "  \"problem\": \"multiclass-classification\",\n",
    "  \"category\": \"EyeScan\",\n",
    "  \"tags\": [\n",
    "    \"retinopathy\"\n",
    "  ],\n",
    "  \"model_train_specs\": {},\n",
    "  \"model_vendor_id\": \"vendor1\",\n",
    "  \"created_timestamp\": \"\",\n",
    "  \"input_shape\": [320, 320]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # use the model zip path recieved from manage/models/upload/zip\n",
    "    'model_zip_path': 'user_models/multiclass-classification/tensorflow/model_61e819ad17ce37cfc59df612', \n",
    "    'only_model': False # This field is inverse to the customize field value mentioned in the github wiki\n",
    "}\n",
    "\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = \"manage/models/db/add\" # put the end point here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "\n",
    "send_request(payload, url, \"post\", params)\n",
    "######\n",
    "# Response\n",
    "#   - status : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff48ead",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Check if the model card is added to the database\n",
    "fetch_model_card_from_db('61e80621b9d1e809e220d52a') # input is model id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddba05a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**&#9654; Case 5: Update FancyNet with new model file only**\n",
    "\n",
    "Case when only model file is uploaded when the model architecture is already existing\n",
    "\n",
    "In this case we require\n",
    "\n",
    "- As customise is false hence we require to ignore `model.py` file upload and only weight file will be added\n",
    "- Namespace will be same as FancyNet architecture\n",
    "\n",
    "\n",
    "<b>Parameter Combination Example</b>\n",
    "<pre>\n",
    "*Type: Classification*\n",
    "*Framework: tensorflow*\n",
    "*Architecture: FancyNet*\n",
    "*customize: False*\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af06b01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Upload the zip folder to the platform\n",
    "upload = FileUpload(accept='.zip', multiple=False)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b56537",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Save the uploaded zip file\n",
    "zip_file_path = os.getcwd() + '/user_model.zip'\n",
    "with open(zip_file_path, 'wb') as output_file: \n",
    "    for uploaded_filename in upload.value:\n",
    "        content = upload.value[uploaded_filename]['content']   \n",
    "        output_file.write(content) \n",
    "print(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f43771",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Send the zip file to the model zip upload api\n",
    "payload = {}\n",
    "\n",
    "params = {\n",
    "    \"framework\": \"tensorflow\", # put the name of the framework here\n",
    "    \"problem\": \"multiclass-classification\", # put the problem with respect to your choice and the combination\n",
    "    \"architecture\": \"fancynet_modelx\"  # put the name of the architecture\n",
    "}\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = 'manage/models/upload/zip' # put the endpoint here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\" \n",
    "\n",
    "files = {'model_zip': open(zip_file_path, 'rb')} # reads the model zip file\n",
    "resp = requests.post(url, files=files, params=params) # posts the request\n",
    "print(resp.json())\n",
    "\n",
    "######\n",
    "# Response\n",
    "#   - model_id : str\n",
    "#   - model_zip_path : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5b11b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# STEP 4: Update the ModelCard in the database\n",
    "\n",
    "# Model card - # Note the fields from UI are different from the fields in the figma \n",
    "# enter the details of the model here.\n",
    "payload = {\n",
    "  \"model_architecture\": \"fancynet_modelx\",\n",
    "  \"model_id\": \"61e80621b9d1e809e220d52a\", # put the model id received from the upload api here\n",
    "  \"model_framework\": \"tensorflow\",\n",
    "  \"framework_version\": \"1\",\n",
    "  \"reqs\": \"tf_reqs.txt\",\n",
    "  \"model_version\": \"1\",\n",
    "  \"model_url\": \"resnet-50.h5\",\n",
    "  \"model_size\": \"150\",\n",
    "  \"class_mappings\": { \"0\" : \"No DR\", \"1\" : \"Mild\", \"2\" : \"Moderate\", \"3\" : \"Severe\", \"4\" : \"Proliferate DR\" },\n",
    "  \"problem\": \"multiclass-classification\",\n",
    "  \"category\": \"EyeScan\",\n",
    "  \"tags\": [\n",
    "    \"retinopathy\"\n",
    "  ],\n",
    "  \"model_train_specs\": {},\n",
    "  \"model_vendor_id\": \"vendor1\",\n",
    "  \"created_timestamp\": \"\",\n",
    "  \"input_shape\": [320, 320]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # use the model zip path recieved from manage/models/upload/zip\n",
    "    'model_zip_path': 'user_models/multiclass-classification/tensorflow/model_61e819ad17ce37cfc59df612', \n",
    "    'only_model': True # This field is inverse to the customize field value mentioned in the github wiki\n",
    "}\n",
    "\n",
    "\n",
    "host_name = 'http://127.0.0.1' # put the host name here\n",
    "port_number = '8015' # put the port number here\n",
    "endpoint = \"manage/models/db/add\" # put the end point here\n",
    "url = f\"{host_name}:{port_number}/{endpoint}\"\n",
    "\n",
    "send_request(payload, url, \"post\", params)\n",
    "######\n",
    "# Response\n",
    "#   - status : str\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb5f52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Check if the model card is added to the database\n",
    "fetch_model_card_from_db('61e80621b9d1e809e220d52a') # input is model id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73dcfe",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: Single prediction using the uploaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032b749",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hostname = 'http://127.0.0.1'  # Enter the URL where the model is deployed\n",
    "port_num = '8000' # Enter the port number\n",
    "endpoint = 'prediction' # Enter the prediction endpoint\n",
    "deploy_id = '' # id of the deployment \n",
    "dataset_id = '' # id of the dataset \n",
    "image_id = ''  # Id of the image referring to image in the Data.Image collection\n",
    "user_transformations = {} # Specific transformation to apply on the image\n",
    "\n",
    "\n",
    "# build the URL\n",
    "url = '{}:{}/{}/{}'.format(hostname, port_num, endpoint, deploy_id)\n",
    "\n",
    "# input to the api\n",
    "json_input = {\n",
    "    \"image_id\": image_id, \n",
    "    \"deploy_id\": deploy_id,\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"user_transformations\": user_transformations\n",
    "}\n",
    "\n",
    "# set headers to api\n",
    "headers = {\n",
    "    'accept': 'application/json', \n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "# Post the data on the api\n",
    "response = requests.post(url, json=json_input, headers=headers)\n",
    "\n",
    "\n",
    "# Print the response\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "    \n",
    "# \"\"\"\n",
    "# Response\n",
    "# ---------\n",
    "# prediction_class: An integer value stating the predicted class for the classification\n",
    "# confidence: A float value stating the confidence of the model for prediction\n",
    "# time_taken: A float value stating the amount of time took for single image prediction\n",
    "# status: An integer value stating the api execution status of the api\n",
    "# prediction_class_mappings: For single predictions, we also need to return human readable class mapping.\n",
    "\n",
    "# \"\"\"\n",
    "## Note: Class wise logits, losses and confidence must return. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029555c6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: Batch prediction using the uploaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127c1df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hostname = 'http://127.0.0.1'  # Enter the URL where the model is deployed\n",
    "port_num = '8000' # Enter the port number\n",
    "endpoint = 'batch/prediction' # Enter the prediction endpoint\n",
    "deploy_id = ''  # id of the deployed model\n",
    "dataset_id = \"\"  # Id of the dataset from which the set of images to chose from\n",
    "user_transformations = {}  # User transformations to apply on the image\n",
    "number_of_images = 64  # Total number of images to subset from the dataset\n",
    "batch_size = 16  # Size of the batch on which data should be splitted for prediction\n",
    "\n",
    "# build the URL\n",
    "url = '{}:{}/{}'.format(hostname, port_num, endpoint)\n",
    "\n",
    "# input to the api\n",
    "json_input = {\n",
    "  \"dataset_id\": dataset_id,\n",
    "  \"user_transformations\": user_transformations,  \n",
    "  \"deploy_id\": deploy_id, \n",
    "  \"n_images\": number_of_images, \n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "\n",
    "# set headers to api\n",
    "headers = headers = {\n",
    "    'accept': 'application/json', \n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "# Post the data on the api\n",
    "response = requests.post(url, json=json_input, headers=headers)\n",
    "\n",
    "\n",
    "# Post the data on the api\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "\n",
    "# \"\"\"\n",
    "# Response\n",
    "# ---------\n",
    "# batch_job_id: Alphanumeric value as a reference to the background running batch prediction\n",
    "# status: A String value with the api status description\n",
    "# code: An integer value for the status code\n",
    "\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e43fc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once You have submitted the batch prediction job, you need to check the status of the batch prediction\n",
    "Follow this tutorial to on how to check the batch prediction status [Tutorial: How to check the batch prediction status](#Tutorial:-How-to-check-the-batch-prediction-status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68913388",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Tutorial: How to check the batch prediction status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76af6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hostname = 'http://127.0.0.1'  # Enter the URL where the model is deployed\n",
    "port_num = '8000' # Enter the port number\n",
    "endpoint = 'batch/status' # Enter the prediction endpoint\n",
    "batch_job_id = \"\" # Id of the batch job received from the batch prediction api\n",
    "\n",
    "\n",
    "# build the URL\n",
    "url = '{}:{}/{}'.format(hostname, port_num, endpoint)\n",
    "\n",
    "# input to the api\n",
    "json_input = {\n",
    "  \"batch_job_id\": batch_job_id\n",
    "}\n",
    "\n",
    "\n",
    "# set headers to api\n",
    "headers = headers = {\n",
    "    'accept': 'application/json', \n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "# Post the data on the api\n",
    "response = requests.post(url, json=json_input, headers=headers)\n",
    "\n",
    "\n",
    "# Post the data on the api\n",
    "print(response.status_code)\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "\n",
    "# \"\"\"\n",
    "# Response\n",
    "# ---------\n",
    "# batch_job_id: Alphanumeric value as a reference to the background running batch prediction\n",
    "# status: A dictionary stating the number of batches done\n",
    "# -- batches_done: Number of batches completed\n",
    "# -- total_batches: Total number of batches\n",
    "# -- status: A string value stating the status of the api\n",
    "# -- batches_failed: Number of batches failed\n",
    "# -- total_images: Total number of batches\n",
    "\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf98067",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
